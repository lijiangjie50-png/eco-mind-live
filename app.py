import streamlit as st
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import dice_ml
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# ==========================================
# 1. Page Config & Caching
# ==========================================
st.set_page_config(layout="wide", page_title="Forest Cover XAI Dashboard")

st.markdown("""
<style>
    .main-header { font-size: 26px; font-weight: bold; color: #1B5E20; }
    .stButton>button { width: 100%; }
</style>
""", unsafe_allow_html=True)

# ç¼“å­˜å‡½æ•°
@st.cache_resource
def load_and_train_model():
    # ---------------------------------------------------------
    # PART A: Load Data
    # ---------------------------------------------------------
    # 1. å®šä¹‰çœŸå®çš„åˆ—åç»“æ„ (é˜²æ­¢æ¨¡æ‹Ÿæ•°æ®åˆ—åå¯¹ä¸ä¸Š)
    cols_continuous = [
        "Elevation", "Aspect", "Slope",
        "Horizontal_Distance_To_Hydrology", "Vertical_Distance_To_Hydrology",
        "Horizontal_Distance_To_Roadways", "Horizontal_Distance_To_Fire_Points",
        "Hillshade_9am", "Hillshade_Noon", "Hillshade_3pm"
    ]
    cols_wilderness = [f"Wilderness_Area{i}" for i in range(1, 5)]
    cols_soil = [f"Soil_Type{i}" for i in range(1, 41)]
    all_feature_names = cols_continuous + cols_wilderness + cols_soil

    try:
        # å°è¯•è¯»å– CSV (åªè¯»å‰ 10000 è¡Œä»¥èŠ‚çœå†…å­˜)
        df = pd.read_csv("covtype.csv", nrows=10000)
    except FileNotFoundError:
        # -----------------------------------------------------
        # å…³é”®ä¿®å¤ï¼šæ¨¡æ‹Ÿæ•°æ®å¿…é¡»ä½¿ç”¨å’ŒçœŸå®æ•°æ®ä¸€æ ·çš„åˆ—åï¼
        # -----------------------------------------------------
        st.warning("âš ï¸ æœªæ‰¾åˆ° covtype.csvï¼Œæ­£åœ¨ä½¿ç”¨ã€æ¨¡æ‹Ÿæ•°æ®ã€‘æ¨¡å¼è¿è¡Œã€‚")
        np.random.seed(42)
        n_samples = 2000
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å­—å…¸
        data_sim = {}
        for col in cols_continuous:
            data_sim[col] = np.random.rand(n_samples) * 100 # éšæœºå€¼
        for col in cols_wilderness + cols_soil:
            data_sim[col] = np.random.randint(0, 2, n_samples) # 0æˆ–1
            
        df = pd.DataFrame(data_sim)
        # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
        df = df[all_feature_names]
        # ç”Ÿæˆç›®æ ‡å˜é‡
        df['Cover_Type'] = np.random.randint(1, 8, n_samples)
        
    X = df.drop(columns=["Cover_Type"], errors='ignore')
    y = df["Cover_Type"]
    
    # ç¡®ä¿ X åªåŒ…å«æˆ‘ä»¬å®šä¹‰çš„ç‰¹å¾åˆ—
    X = X[all_feature_names]

    # Stratify split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # ---------------------------------------------------------
    # PART B: Train Model
    # ---------------------------------------------------------
    model = RandomForestClassifier(
        n_estimators=100, # ç¨å¾®å‡å°ä¸€ç‚¹ä»¥é˜²è¶…æ—¶
        random_state=42,
        n_jobs=-1,
        class_weight="balanced"
    )
    model.fit(X_train, y_train)

    # ---------------------------------------------------------
    # PART C: Setup Explainer & DiCE
    # ---------------------------------------------------------
    explainer = shap.TreeExplainer(model)

    # DiCE Setup
    valid_continuous = [c for c in cols_continuous if c in X_train.columns]

    d = dice_ml.Data(
        dataframe=pd.concat([X_train, y_train], axis=1),
        continuous_features=valid_continuous,
        outcome_name="Cover_Type"
    )
    
    m = dice_ml.Model(model=model, backend="sklearn", model_type="classifier")
    dice_exp = dice_ml.Dice(d, m, method="random")

    return model, explainer, dice_exp, X_train, valid_continuous

# åŠ è½½æ¨¡å‹
with st.spinner('System Initializing... (Training Model & Loading XAI Engine)'):
    model, explainer, dice_exp, X_train, continuous_cols = load_and_train_model()

# ==========================================
# 2. Sidebar: Inputs
# ==========================================
st.sidebar.header("ğŸ“ Feature Input")

# è·å–è®­ç»ƒæ•°æ®çš„åˆ—åç»“æ„ (è¿™æ˜¯æ ‡å‡†ç­”æ¡ˆ)
feature_names_ref = X_train.columns.tolist()

def input_feature(label, default, min_v, max_v):
    return st.sidebar.slider(label, min_v, max_v, default)

elevation = input_feature("Elevation", 3210, 1800, 4000)
aspect = input_feature("Aspect", 192, 0, 360)
slope = input_feature("Slope", 10, 0, 60)
h_hydro = input_feature("Horz. Dist to Hydro", 90, 0, 1500)
v_hydro = input_feature("Vert. Dist to Hydro", 10, -200, 600)
road = input_feature("Horz. Dist to Road", 3144, 0, 7000)
fire = input_feature("Horz. Dist to Fire", 339, 0, 7000)
shade9 = input_feature("Hillshade 9am", 219, 0, 255)
shade12 = input_feature("Hillshade Noon", 248, 0, 255)
shade3 = input_feature("Hillshade 3pm", 162, 0, 255)

st.sidebar.markdown("---")

soil_options = [f"Soil_Type{i}" for i in range(1, 41)]
selected_soil = st.sidebar.selectbox("Soil Type", soil_options, index=28)

wilderness_options = [f"Wilderness_Area{i}" for i in range(1, 5)]
selected_wild = st.sidebar.selectbox("Wilderness Area", wilderness_options, index=0)

# æ„å»ºè¾“å…¥å‘é‡
input_data = {}
# å…ˆå…¨éƒ¨å¡« 0
for col in feature_names_ref:
    input_data[col] = 0

# å¡«å…¥æ»‘å—çš„å€¼
input_data['Elevation'] = elevation
input_data['Aspect'] = aspect
input_data['Slope'] = slope
input_data['Horizontal_Distance_To_Hydrology'] = h_hydro
input_data['Vertical_Distance_To_Hydrology'] = v_hydro
input_data['Horizontal_Distance_To_Roadways'] = road
input_data['Horizontal_Distance_To_Fire_Points'] = fire
input_data['Hillshade_9am'] = shade9
input_data['Hillshade_Noon'] = shade12
input_data['Hillshade_3pm'] = shade3

# å¡«å…¥ä¸‹æ‹‰èœå•çš„å€¼ (One-Hot)
if selected_soil in input_data: input_data[selected_soil] = 1
if selected_wild in input_data: input_data[selected_wild] = 1

# è½¬ä¸º DataFrame
query_df = pd.DataFrame([input_data])

# ==========================================
# å…³é”®ä¿®å¤ (CRITICAL FIX)
# ==========================================
# å¼ºåˆ¶è®© query_df çš„åˆ—é¡ºåºå’Œåå­—å®Œå…¨åŒ¹é…è®­ç»ƒæ—¶çš„ X_train
# è¿™ä¸€æ­¥ä¼šä¸¢å¼ƒæ‰ä»»ä½•å¤šä½™çš„åˆ—ï¼Œå¹¶è‡ªåŠ¨æŒ‰ç…§æ­£ç¡®é¡ºåºæ’åˆ—
query_df = query_df[feature_names_ref] 

# ==========================================
# 3. Main Dashboard
# ==========================================
st.markdown('<div class="main-header">ğŸŒ² Forest Cover Type XAI Dashboard</div>', unsafe_allow_html=True)

# Section 1: Prediction
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### 1. Prediction")
    prediction = model.predict(query_df)[0]
    probs = model.predict_proba(query_df)[0]
    confidence = np.max(probs)
    
    class_names = {1: "Spruce/Fir", 2: "Lodgepole Pine", 3: "Ponderosa Pine", 
                   4: "Cottonwood/Willow", 5: "Aspen", 6: "Douglas-fir", 7: "Krummholz"}
    pred_name = class_names.get(prediction, f"Type {prediction}")

    st.metric("Predicted Class", f"{pred_name}")
    st.metric("Confidence", f"{confidence*100:.1f}%")
    
    if prediction == 1:
        st.info("â„¹ï¸ High Elevation Zone")
    elif prediction == 2:
        st.warning("â„¹ï¸ Fire Risk: High")

# Section 2: SHAP
with col2:
    st.markdown("### 2. Explanation (SHAP)")
    shap_values = explainer(query_df)
    class_idx = int(prediction) - 1
    
    # ç”»å›¾
    fig, ax = plt.subplots(figsize=(8, 4))
    # æ³¨æ„ï¼šä½¿ç”¨å½“å‰é¢„æµ‹ç±»çš„ SHAP å€¼
    shap.plots.waterfall(shap_values[0, :, class_idx], show=False, max_display=7)
    st.pyplot(fig)

st.markdown("---")

# Section 3: DiCE
st.markdown("### 3. Actionable Insights (DiCE)")
st.write(f"Scenario: How to change from **{pred_name}** to another type?")

target_class = st.selectbox("Select Target Class:", list(class_names.keys()), index=2) # Default Type 3

if st.button("Generate Counterfactuals"):
    with st.spinner("Calculating..."):
        try:
            cf = dice_exp.generate_counterfactuals(
                query_df,
                total_CFs=3,
                desired_class=int(target_class),
                features_to_vary=continuous_cols 
            )
            cf_df = cf.visualize_as_dataframe(show_only_changes=False)
            st.dataframe(cf_df)
        except Exception as e:
            st.error(f"Could not generate counterfactuals: {e}")
